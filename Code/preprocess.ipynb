{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\WorkSpace\\Python\\Taobao-live-product-identification\\Live_data\\Live_demo_20200117\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "dir_root = \"D:\\\\WorkSpace\\\\Python\\\\Taobao-live-product-identification\"\n",
    "dir_name = \"D:\\\\WorkSpace\\\\Python\\\\Taobao-live-product-identification\\\\Live_data\"\n",
    "dir_dataset = os.listdir(dir_name)\n",
    "for f in dir_dataset:\n",
    "    print(dir_name + os.sep + f)\n",
    "\n",
    "# 这里是因为我只下载了part1,为了后面可以加上另外五个part,所以加上一个for\n",
    "# for i,f in enumerate(dir_dataset):\n",
    "f = dir_dataset[0]\n",
    "dir_six_parts = os.listdir(dir_name + os.sep + f)\n",
    "dir_six_parts.sort(reverse=False)\n",
    "\n",
    "dir_image = dir_name + os.sep + f + os.sep + dir_six_parts[0]\n",
    "dir_image_annotation = dir_name + os.sep + f + os.sep + dir_six_parts[1]\n",
    "dir_image_text = dir_name + os.sep + f + os.sep + dir_six_parts[2]\n",
    "dir_video = dir_name + os.sep + f + os.sep + dir_six_parts[3]\n",
    "dir_video_annotation = dir_name + os.sep + f + os.sep + dir_six_parts[4]\n",
    "dir_video_frame = dir_name + os.sep + f + os.sep + dir_six_parts[5]\n",
    "dir_video_text = dir_name + os.sep + f + os.sep + dir_six_parts[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "    item_id img_name  label  viewpoint  display  instance_id  x_min  y_min  \\\n",
      "0    000001    0.jpg   长款外套        1.0      0.0   20000101.0  235.0   60.0   \n",
      "1    000001    1.jpg   长款外套        0.0      0.0   20000101.0    3.0  195.0   \n",
      "2    000001    2.jpg   长款外套        0.0      0.0   20000101.0  274.0  116.0   \n",
      "3    000001    3.jpg   长款外套        2.0      0.0   20000101.0    0.0   71.0   \n",
      "4    000001    4.jpg   None        NaN      NaN          NaN    NaN    NaN   \n",
      "..      ...      ...    ...        ...      ...          ...    ...    ...   \n",
      "108  000025    0.jpg  短袖Top        0.0      0.0   20002501.0  160.0   38.0   \n",
      "109  000025    1.jpg  短袖Top        0.0      0.0   20002501.0  158.0   45.0   \n",
      "110  000025    2.jpg   None        NaN      NaN          NaN    NaN    NaN   \n",
      "111  000025    3.jpg   None        NaN      NaN          NaN    NaN    NaN   \n",
      "112  000025    4.jpg   None        NaN      NaN          NaN    NaN    NaN   \n",
      "\n",
      "      x_max   y_max                                           img_path  \\\n",
      "0     782.0  1348.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "1    1078.0  1440.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "2     837.0  1355.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "3     827.0  1433.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "4       NaN     NaN  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "..      ...     ...                                                ...   \n",
      "108   638.0   761.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "109   658.0   758.0  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "110     NaN     NaN  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "111     NaN     NaN  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "112     NaN     NaN  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "\n",
      "                                         img_text_path  \n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "1    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "4    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "..                                                 ...  \n",
      "108  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "109  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "110  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "111  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "112  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "\n",
      "[113 rows x 12 columns]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 首先把json都弄出来处理成一个df 每一个json就是一条信息\n",
    "image_json_dic_list = []\n",
    "for img_id in os.listdir(dir_image_annotation):\n",
    "    dir_fold = dir_image_annotation + os.sep + img_id\n",
    "    jsons = os.listdir(dir_fold)\n",
    "    for i,img_json in enumerate(jsons):\n",
    "        f = open(dir_fold + os.sep + img_json,'r')\n",
    "        json_file = json.load(f)\n",
    "        json_file['img_path'] = dir_image + os.sep + img_id + os.sep + str(i) + \".jpg\"\n",
    "        json_file['img_text_path'] = dir_image_text + os.sep + img_id + '.txt'\n",
    "        image_json_dic_list.append(json_file)\n",
    "# 开始将字典list转化为纯list\n",
    "image_json_list = []\n",
    "for i in image_json_dic_list:\n",
    "    l = []\n",
    "    if len(i['annotations']) != 0:\n",
    "        for j in range(0,len(i['annotations'])):\n",
    "            if len(i['annotations'][j]['box']) == 4:\n",
    "                l = [i['item_id'],i['img_name'],\n",
    "                 i['annotations'][j]['label'],\n",
    "                 i['annotations'][j]['viewpoint'],\n",
    "                 i['annotations'][j]['display'],\n",
    "                 i['annotations'][j]['instance_id'],\n",
    "                 i['annotations'][j]['box'][0],\n",
    "                 i['annotations'][j]['box'][1],\n",
    "                 i['annotations'][j]['box'][2],\n",
    "                 i['annotations'][j]['box'][3],\n",
    "                 i['img_path'],i['img_text_path']]\n",
    "            elif len(i['annotations'][j]['box']) == 0:\n",
    "                l = [i['item_id'],i['img_name'],\n",
    "                 i['annotations'][j]['label'],\n",
    "                 i['annotations'][j]['viewpoint'],\n",
    "                 i['annotations'][j]['display'],\n",
    "                 i['annotations'][j]['instance_id'],\n",
    "                 None,None,None,None,\n",
    "                 i['img_path'],i['img_text_path']]\n",
    "    elif len(i['annotations']) == 0:\n",
    "        l = [i['item_id'],i['img_name'],\n",
    "             None,None,None,None,\n",
    "             None,None,None,None,\n",
    "             i['img_path'],i['img_text_path']]\n",
    "    image_json_list.append(l)\n",
    "# 将list转化为df 存入csv中\n",
    "df_img = pd.DataFrame(image_json_list,columns=['item_id','img_name','label',\n",
    "                                           'viewpoint','display','instance_id',\n",
    "                                           'x_min','y_min','x_max','y_max',\n",
    "                                               'img_path','img_text_path'])\n",
    "print(df_img)\n",
    "df_img.to_csv(dir_root + os.sep + 'Temp-File' + os.sep + 'img.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import cv2\n",
    "# 把视频中的帧都抽取出来\n",
    "for video_json in os.listdir(dir_video_annotation):\n",
    "    # dir_ = dir_video + os.sep + video_json[:6] + \".mp4\"\n",
    "    cap = cv2.VideoCapture(dir_video + os.sep + video_json[:6] + \".mp4\")\n",
    "    dir_video_json = dir_video_annotation + os.sep + video_json\n",
    "    f = open(dir_video_json,'r')\n",
    "    video_dic = json.load(f)\n",
    "    for frame in video_dic['frames']:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, float(frame['frame_index']))\n",
    "        if cap.isOpened():\n",
    "            if_success , spe_frame = cap.read()\n",
    "            new_file_path =  dir_video_frame + os.sep + str(video_dic['video_id']) + \"_\" + str(frame['frame_index']) + \".jpg\"\n",
    "            # print(cv2.imencode('.jpg', spe_frame))\n",
    "            cv2.imencode('.jpg', spe_frame)[1].tofile(new_file_path)\n",
    "    cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "    video_id  frame_index  label  viewpoint  display  instance_id  x_min  \\\n",
      "0     000001            0   长款外套          0        1     20000101    214   \n",
      "1     000001            0     长裤          0        1            0    289   \n",
      "2     000001           40   长款外套          0        1     20000101    248   \n",
      "3     000001           80   长款外套          0        1     20000101    128   \n",
      "4     000001          120   长款外套          0        1     20000101    242   \n",
      "..       ...          ...    ...        ...      ...          ...    ...   \n",
      "463   000025          280     中裤          0        1            0    207   \n",
      "464   000025          320  短袖Top          0        1     20002501    126   \n",
      "465   000025          320     中裤          0        1            0    103   \n",
      "466   000025          360  长袖Top          0        1     20002501    143   \n",
      "467   000025          360     中裤          0        1            0    152   \n",
      "\n",
      "     y_min  x_max  y_max                                         frame_path  \\\n",
      "0      526    519    996  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "1      988    422   1216  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "2      528    551   1043  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "3      528    461   1056  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "4      519    507   1036  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "..     ...    ...    ...                                                ...   \n",
      "463    667    416    953  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "464    482    395    720  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "465    672    371    982  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "466    473    390    676  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "467    664    388    983  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "\n",
      "                                       video_text_path  \n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "1    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "4    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "..                                                 ...  \n",
      "463  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "464  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "465  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "466  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "467  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "\n",
      "[468 rows x 12 columns]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "#把video的json中的每个帧的annotation抽取出来\n",
    "video_json_list = []\n",
    "for video_json in os.listdir(dir_video_annotation):\n",
    "    dir_video_json = dir_video_annotation + os.sep + video_json\n",
    "    dir_frame = dir_video_frame + os.sep + video_json[:6] + \"_\"\n",
    "    f = open(dir_video_json,'r')\n",
    "    video_dic = json.load(f)\n",
    "    for frame in video_dic['frames']:\n",
    "        if len(frame['annotations']) != 0:\n",
    "            for j in range(0,len(frame['annotations'])):\n",
    "                video_json_list.append([video_dic['video_id'],frame['frame_index'],\n",
    "                                    frame['annotations'][j]['label'],\n",
    "                                    frame['annotations'][j]['viewpoint'],\n",
    "                                    frame['annotations'][j]['display'],\n",
    "                                    frame['annotations'][j]['instance_id'],\n",
    "                                    frame['annotations'][j]['box'][0], \n",
    "                                    frame['annotations'][j]['box'][1],\n",
    "                                    frame['annotations'][j]['box'][2],\n",
    "                                    frame['annotations'][j]['box'][3],\n",
    "                                    dir_frame+str(frame['frame_index'])+'.jpg',\n",
    "                                    dir_video_text+os.sep+video_json[:6]+'.txt'])\n",
    "        # elif len(frame['annotations']) == 0:\n",
    "df_video = pd.DataFrame(video_json_list,columns=['video_id','frame_index','label',\n",
    "                                                 'viewpoint','display','instance_id',\n",
    "                                                 'x_min','y_min','x_max','y_max',\n",
    "                                                 'frame_path','video_text_path'])\n",
    "print(df_video)\n",
    "df_video.to_csv(dir_root + os.sep + 'Temp-File' + os.sep + 'video.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0  video_id  frame_index  label  viewpoint  display  \\\n",
      "0             0         1            0   长款外套          0        1   \n",
      "2             2         1           40   长款外套          0        1   \n",
      "3             3         1           80   长款外套          0        1   \n",
      "4             4         1          120   长款外套          0        1   \n",
      "5             5         1          160   长款外套          0        1   \n",
      "..          ...       ...          ...    ...        ...      ...   \n",
      "458         458        25          200  短袖Top          0        1   \n",
      "460         460        25          240  短袖Top          0        1   \n",
      "462         462        25          280  短袖Top          0        1   \n",
      "464         464        25          320  短袖Top          0        1   \n",
      "466         466        25          360  长袖Top          0        1   \n",
      "\n",
      "     instance_id  x_min  y_min  x_max  y_max  \\\n",
      "0       20000101    214    526    519    996   \n",
      "2       20000101    248    528    551   1043   \n",
      "3       20000101    128    528    461   1056   \n",
      "4       20000101    242    519    507   1036   \n",
      "5       20000101     74    521    626   1046   \n",
      "..           ...    ...    ...    ...    ...   \n",
      "458     20002501    201    499    443    688   \n",
      "460     20002501    225    496    445    726   \n",
      "462     20002501    259    510    451    702   \n",
      "464     20002501    126    482    395    720   \n",
      "466     20002501    143    473    390    676   \n",
      "\n",
      "                                            frame_path  \\\n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "4    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "5    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "..                                                 ...   \n",
      "458  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "460  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "462  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "464  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "466  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "\n",
      "                                       video_text_path  \n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "4    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "5    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "..                                                 ...  \n",
      "458  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "460  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "462  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "464  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "466  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "\n",
      "[272 rows x 13 columns]\n",
      "     Unnamed: 0  item_id img_name  \\\n",
      "0             0        1    0.jpg   \n",
      "1             1        1    1.jpg   \n",
      "2             2        1    2.jpg   \n",
      "3             3        1    3.jpg   \n",
      "8             8        2    3.jpg   \n",
      "..          ...      ...      ...   \n",
      "101         101       23    3.jpg   \n",
      "104         104       24    1.jpg   \n",
      "107         107       24    4.jpg   \n",
      "108         108       25    0.jpg   \n",
      "109         109       25    1.jpg   \n",
      "\n",
      "                                                 label  viewpoint  display  \\\n",
      "0    [[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]        1.0      0.0   \n",
      "1    [[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "2    [[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "3    [[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]        2.0      0.0   \n",
      "8    [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]]        1.0      0.0   \n",
      "..                                                 ...        ...      ...   \n",
      "101  [[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]        2.0      1.0   \n",
      "104  [[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "107  [[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "108  [[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "109  [[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]        0.0      0.0   \n",
      "\n",
      "     instance_id  x_min  y_min   x_max   y_max  \\\n",
      "0     20000101.0  235.0   60.0   782.0  1348.0   \n",
      "1     20000101.0    3.0  195.0  1078.0  1440.0   \n",
      "2     20000101.0  274.0  116.0   837.0  1355.0   \n",
      "3     20000101.0    0.0   71.0   827.0  1433.0   \n",
      "8     20000201.0  105.0  155.0   691.0   616.0   \n",
      "..           ...    ...    ...     ...     ...   \n",
      "101   20002301.0  320.0  137.0   492.0   663.0   \n",
      "104   20002401.0  230.0   78.0   572.0   728.0   \n",
      "107   20002401.0  230.0   76.0   571.0   728.0   \n",
      "108   20002501.0  160.0   38.0   638.0   761.0   \n",
      "109   20002501.0  158.0   45.0   658.0   758.0   \n",
      "\n",
      "                                              img_path  \\\n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "1    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "8    D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "..                                                 ...   \n",
      "101  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "104  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "107  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "108  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "109  D:\\WorkSpace\\Python\\Taobao-live-product-identi...   \n",
      "\n",
      "                                         img_text_path  \n",
      "0    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "1    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "2    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "3    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "8    D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "..                                                 ...  \n",
      "101  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "104  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "107  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "108  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "109  D:\\WorkSpace\\Python\\Taobao-live-product-identi...  \n",
      "\n",
      "[79 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 处理掉 instance_id 为0的数据\n",
    "df_video = pd.read_csv(dir_root + os.sep + 'Temp-File' + os.sep + 'video.csv')\n",
    "df_video = df_video[df_video['instance_id']!=0]\n",
    "print(df_video)\n",
    "df_video.to_csv(dir_root + os.sep + 'Temp-File' + os.sep +'Data' + os.sep + 'video_processed.csv')\n",
    "\n",
    "df_img = pd.read_csv(dir_root + os.sep + 'Temp-File' + os.sep + 'img.csv')\n",
    "# 去掉为空的行后期需要改\n",
    "df_img = df_img[df_img['label'].notnull()]  # 去除label为空的行\n",
    "df_img = df_img[df_img['instance_id']!=0]   # 去除instance_id 为0的\n",
    "# 转化label为独热编码 这个只有一个特征，就不用复制的sklearn了\n",
    "from sklearn import preprocessing\n",
    "df_img['label'].replace('短袖Top','[[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)   # inplace=True代表修改原dataframe\n",
    "df_img['label'].replace('长袖Top','[[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短袖衬衫','[[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长袖衬衫','[[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('背心上衣','[[0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('吊带上衣','[[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('无袖上衣','[[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短外套','[[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短马甲','[[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长袖连衣裙','[[0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短袖连衣裙','[[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('无袖连衣裙','[[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长马甲','[[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长外套','[[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "# 同长外套\n",
    "df_img['label'].replace('长款外套','[[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('连体衣','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('古风','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短裙','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('中等半身裙','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('中等半身裙（及膝）','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长半身裙','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('短裤','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]]',inplace=True)\n",
    "df_img['label'].replace('中裤','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]]',inplace=True)\n",
    "df_img['label'].replace('长裤','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]]',inplace=True)\n",
    "df_img['label'].replace('背带裤','[[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]]',inplace=True)\n",
    "\n",
    "print(df_img)\n",
    "df_img.to_csv(dir_root + os.sep + 'Temp-File' + os.sep +'Data' + os.sep + 'img_processed.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14寸(16:9):长:30.993226100148974  高:17.433689681333796\n",
      "面积:540.3262860534126\n",
      "13寸(3:2):长:27.474300719035604  高:18.316200479357068\n",
      "面积:503.2248000000001\n",
      "15.6寸(16:9):长:34.535309083023144  高:19.42611135920052\n",
      "16.1寸(16:9):长:35.64221001517132  高:20.04874313353387\n"
     ]
    }
   ],
   "source": [
    "inch = 2.54\n",
    "meta = 14*inch/((16*16+9*9)**0.5)\n",
    "print(\"14寸(16:9):长:\"+str(meta*16)+\"  高:\"+str(meta*9))\n",
    "print(\"面积:\"+str(meta**2*16*9))\n",
    "\n",
    "meta = 13*inch/((3*3+2*2)**0.5)\n",
    "print(\"13寸(3:2):长:\"+str(meta*3)+\"  高:\"+str(meta*2))\n",
    "print(\"面积:\"+str(meta**2*6))\n",
    "\n",
    "meta = 15.6*inch/((16*16+9*9)**0.5)\n",
    "print(\"15.6寸(16:9):长:\"+str(meta*16)+\"  高:\"+str(meta*9))\n",
    "\n",
    "meta = 16.1*inch/((16*16+9*9)**0.5)\n",
    "print(\"16.1寸(16:9):长:\"+str(meta*16)+\"  高:\"+str(meta*9))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([False False  True], shape=(3,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "input = tf.constant(np.random.rand(3,4), tf.float32)\n",
    "k = 2   #targets对应的索引是否在最大的前k(2)个数据中\n",
    "output = tf.math.in_top_k( [3,3,3],input, k)\n",
    "print(output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([0.5,0.4,0.6])\n",
    "b = np.array([True,False,True])\n",
    "print((a>0.5).astype(int))\n",
    "print((b).astype(int))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}